<!DOCTYPE html SYSTEM "about:legacy-compat">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
	
	<title>Article Discussion: Bigler's Review of Validity Testing</title>
	<meta name="author" content="John Denning, Ph.D.">
	<meta name="category" content="Article">
	<meta name="date" content="10/15/2014">
	<meta name="tags" content="Research, Review, Validity">
<!--#include virtual="${Base_URL}/templates/head.html" --></head>
<body><!--#include virtual="${Base_URL}/templates/header.html" --><h1 class="page-title">Article Discussion: Bigler's Review of Validity Testing</h1>
<div class="author">Written By: John Denning, Ph.D.</div>
<div class="date">Published On: 10/15/2014</div><!--#include virtual="${Base_URL}/cgi/tags.cgi" -->

<h2 id="let&#8217;sagree">Let&#8217;s agree&#8230;</h2>

<p>Dr. Erin Bigler (2014) covers a lot of ground with <em><a href="http://informahealthcare.com/doi/abs/10.3109/02699052.2014.947627?journalCode=bij">&#8220;Effort, symptom validity testing, performance validity testing and traumatic brain injury&#8221;</a></em>, his overview of performance validity testing (PVT) that places special emphasis on how TBI-related neurological impairment/damage could influence interpretation of PVTs. Specifically, he attempts to highlight the interpretive challenges of those individuals falling in the &#8220;border-zone&#8221; on PVTs. The term &#8220;border-zone&#8221; is used to describe scores that are below empirically-based cut-offs, but well above chance levels of performance. </p>

<p>I think most would agree with Dr. Bigler that interpretation of border-zone PVT failures may not always be straightforward when compared to below chance performance (a clearer indicator of invalid performance) or comfortably passing validity measures (likely indicating valid test performance). He also makes valid points about the inevitable lack of precision with cut scores for any one test and their rigid interpretation in isolation. Most clinicians would also agree that failed PVTs do not negate the fact that: an injury occurred, there is imaging evidence of brain injury, or there may be residual cognitive deficits. </p>

<p>A recurrent theme throughout the review is that most clinicians determine the validity of an individual&#8217;s performance based on rigid cut-offs <em>only</em>. In fact, most clinicians utilize some variation of the Slick et al. criteria when interpreting cognitive test data (e.g., integrating multiple pieces of information from a variety of sources before one makes a conclusion about performance validity). The Slick criteria include the assessment of inconsistencies in presentation as well as interpretation of multiple PVTs, which then guide clinical judgment. </p>

<p>Again, most would agree with Dr. Bigler that PVTs can be failed by those with neurological conditions directly attributed to the extent/severity of the neurological disorder (e.g., TBI, dementia, mental retardation, psychotic disorders, Huntington&#8217;s disease). He mentioned that if those with even a severe TBI are able to repeat simple digits forward/backward, it stands to reason that those reporting a remote history of mTBI who cannot complete this task are displaying invalid performance. He appears to ignore this general dose-response principle, however, when providing several individual examples and research findings throughout the review, wherein patients with minimal to no cognitive deficits fail PVTs. </p>

<h2 id="todisagree">&#8230;to disagree</h2>

<p>In contrast, in samples with clear neurological diagnoses and suspected impairments (refractory epilepsy, multiple sclerosis), he decides to essentially ignore any possible relevance of PVT failures. When memory performance falls within the expected &#8220;direction of impairment&#8221; (below the average range), PVT results are viewed as &#8220;irrelevant.&#8221; I believe most clinicians would disagree with this assumption and find that the severity of cognitive compromise is highly relevant when making determinations about a patient&#8217;s status (e.g., presence/severity of dementia, need for interventions, extent of disability, etc.) or increasing the knowledge base about a clinical condition (e.g., tracking the severity of cognitive deficits after sport concussion over time).</p>
<!-- examples -->

<p>Dr. Bigler provides a series of theoretical explanations for why border-zone PVT failure could indicate one&#8217;s true level of neurological compromise (due to deficits in memory/attentional systems and motivational behaviors). Examples include: illness beliefs/diagnosis threat, Somatic Symptom Disorder, frontal lobe syndrome, depression, mental fatigue, PTSD, ADHD, white matter dysfunction, hippocampal pathology, basal ganglia degeneration, default mode network disruptions, PVTs requiring effortful processing, and any combination of the above. </p>

<p>In his review, Dr. Bigler appears to be overly-focused on the many possible combinations of explanations, rather than relying on the dose-response approach he noted earlier<a href="#fn:1" id="fnref:1" title="see footnote" class="footnote">[1]</a>. Individuals with conditions that result in minimal to no cognitive compromise (on very challenging cognitive measures) should not perform poorly on easy PVTs when compared to those with more severe neurological impairments (who frequently pass PVTs). For example, when he presents several examples of PVT failure in those with documented neurological injury (e.g., using neuroimaging, biochemical, or functional imaging techniques), these same neurological underpinnings should also lead to even worse performance on more challenging cognitive measures that require greater neural recruitment. This pattern would be neurologically consistent with a dose-response impairment profile; however, several of Dr. Bigler&#8217;s examples of PVT failure either (a) do not mention performance on more complex cognitive tasks or (b) ignore the fact that performance was within the average range or higher. One may also begin to question Dr. Bigler&#8217;s often implied 1:1 relationship between abnormalities noted on neuroimaging, fMRI, and/or MRS and performance on cognitive testing as several cases (and research samples, see Hetherington, 2014) often performed well within the average range. </p>

<p>In a section entitled, &#8220;A mTBI case study&#8230;The prototype problem for the SVT researcher and clinician,&#8221; he presents a case that is neither mild (GCS = 5, with neuroimaging abnormalities) nor prototypical (essentially above average IQ and memory performance) who performed at cut-offs and below on PVTs. If the individual in question was significantly impaired with daily functioning,<a href="#fn:2" id="fnref:2" title="see footnote" class="footnote">[2]</a> the reader may entertain the idea that low PVTs were possibly due (in part) to organic pathology; however, failed PVTs due to residual brain dysfunction would not be consistent with his above average cognitive/memory abilities on more complex cognitive testing. The individual&#8217;s statement that he &#8220;doesn&#8217;t give a shit about things!&#8221; might also be more suggestive of depression and a lack of persistence. Most would also not conclude that test scores were completely invalid but performance may slightly underestimate his true level of ability.</p>

<p>At one point Dr. Bigler expresses great concern about the field of neuropsychology in general when discussing the high rates of PVT failure (up to 60%) in a very specific population (Military and Veteran samples). Specifically, he appears worried that failed test results in these populations may render assessments &#8220;non-interpretable&#8221; and that &#8220;these high levels of [PVT] failure only mean invalid test performance.&#8221; It is unclear why he is in such distress over the relatively high rates of invalid testing in a group of individuals often claiming remote mTBI-related cognitive impairments in settings with clear external incentives for under-performance. If anything, being able to utilize empirically-based PVT cut-offs to help determine valid cognitive test results in Military and Veteran populations may have in fact elevated neuropsychology to the forefront of research, assessment, and clinical interventions for combat Veterans over the past decade.</p>

<h2 id="unfortunatelyfortunately">Unfortunately/Fortunately</h2>

<p>Throughout the review, Dr. Bigler poses 61 questions to the reader<a href="#fn:3" id="fnref:3" title="see footnote" class="footnote">[3]</a> in an apparent attempt to show that we know very little about the impact of a variety of biological, psychiatric, and/or environmental factors on PVT performance. Granted, several questions are relevant to the field, including what types of PVTs and cut-offs should be used with specific patient populations, possible order effects of PVTs within a test battery, and how many PVTs should be administered/interpreted. Nevertheless, after considering most of his questions, readers may be able to reasonably interpret &#8220;border-zone&#8221; PVT failures by referring to the edited works of Kyle Boone, Glen Larrabbee, Dominic Carone/Shane Bush, and Joel Morgan/Jerry Sweet, which nicely summarize the field of modern PVT assessment. </p>

<div class="footnotes">
<hr>
<ol>

<li id="fn:1">
<p>that PVTs are failed in direct relation to the extent of the neurological disorder. <a href="#fnref:1" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

<li id="fn:2">
<p>He was not. <a href="#fnref:2" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

<li id="fn:3">
<p>Ed: this is accurate - there actually are <em>61 questions</em> put forth by Dr. Bigler. <a href="#fnref:3" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

</ol>
</div>


<!--#include virtual="${Base_URL}/templates/footer.html" --></body>
</html>
